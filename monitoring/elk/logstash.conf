# Logstash Configuration for WhatsApp Clone
# Processes logs from all microservices and sends to Elasticsearch

input {
  # TCP input for application logs
  tcp {
    port => 5000
    codec => json_lines
    type => "application"
  }

  # HTTP input for structured logs
  http {
    port => 5001
    codec => json
    type => "http"
  }

  # Beats input (if using Filebeat)
  # beats {
  #   port => 5044
  #   type => "beats"
  # }

  # Docker logs via syslog
  # syslog {
  #   port => 5514
  #   type => "docker"
  # }
}

filter {
  # Parse JSON logs
  if [type] == "application" {
    json {
      source => "message"
      target => "parsed"
    }

    # Extract common Spring Boot fields
    if [parsed] {
      mutate {
        add_field => {
          "[@metadata][service]" => "%{[parsed][service_name]}"
          "[@metadata][level]" => "%{[parsed][level]}"
        }
      }

      # Extract timestamp
      if [parsed][timestamp] {
        date {
          match => [ "[parsed][timestamp]", "ISO8601" ]
          target => "@timestamp"
        }
      }

      # Extract correlation ID for request tracing
      if [parsed][trace_id] {
        mutate {
          add_field => { "trace_id" => "%{[parsed][trace_id]}" }
        }
      }

      if [parsed][span_id] {
        mutate {
          add_field => { "span_id" => "%{[parsed][span_id]}" }
        }
      }
    }
  }

  # Filter by log level
  if [@metadata][level] {
    mutate {
      add_field => { "log_level" => "%{[@metadata][level]}" }
    }
  }

  # Add service tags
  if [container_name] {
    if [container_name] =~ /gateway/ {
      mutate {
        add_field => { 
          "service" => "gateway"
          "layer" => "api-gateway"
        }
      }
    } else if [container_name] =~ /user-service/ {
      mutate {
        add_field => { 
          "service" => "user"
          "layer" => "business"
        }
      }
    } else if [container_name] =~ /chat-service/ {
      mutate {
        add_field => { 
          "service" => "chat"
          "layer" => "business"
        }
      }
    } else if [container_name] =~ /notification-service/ {
      mutate {
        add_field => { 
          "service" => "notification"
          "layer" => "business"
        }
      }
    } else if [container_name] =~ /message-processor/ {
      mutate {
        add_field => { 
          "service" => "message-processor"
          "layer" => "processing"
        }
      }
    } else if [container_name] =~ /scheduled-jobs/ {
      mutate {
        add_field => { 
          "service" => "scheduled-jobs"
          "layer" => "background"
        }
      }
    }
  }

  # Parse Java stack traces
  if [message] =~ /^(\s+at\s|Caused by:)/ {
    mutate {
      add_tag => [ "stack_trace" ]
    }
  }

  # Parse HTTP access logs
  if [type] == "access" {
    grok {
      match => { 
        "message" => "%{IPORHOST:client_ip} - - \[%{HTTPDATE:timestamp}\] \"%{WORD:http_method} %{URIPATHPARAM:request_path} HTTP/%{NUMBER:http_version}\" %{NUMBER:status_code} %{NUMBER:response_size} %{QS:referrer} %{QS:user_agent} %{NUMBER:response_time:float}"
      }
    }

    date {
      match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
    }

    # Convert status code to integer
    mutate {
      convert => { "status_code" => "integer" }
      convert => { "response_size" => "integer" }
    }

    # Add response status category
    if [status_code] >= 500 {
      mutate {
        add_field => { "status_category" => "error" }
        add_tag => [ "http_error" ]
      }
    } else if [status_code] >= 400 {
      mutate {
        add_field => { "status_category" => "client_error" }
        add_tag => [ "http_client_error" ]
      }
    } else if [status_code] >= 300 {
      mutate {
        add_field => { "status_category" => "redirect" }
      }
    } else {
      mutate {
        add_field => { "status_category" => "success" }
      }
    }
  }

  # Parse database slow query logs
  if [message] =~ /slow query/ {
    mutate {
      add_tag => [ "slow_query" ]
    }
  }

  # Parse RabbitMQ logs
  if [service] == "rabbitmq" {
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{LOGLEVEL:level}\] %{GREEDYDATA:log_message}"
      }
    }
  }

  # Remove unnecessary fields
  mutate {
    remove_field => [ "[parsed]", "[@metadata]" ]
  }

  # Add hostname and environment
  mutate {
    add_field => {
      "environment" => "docker-desktop"
      "cluster" => "whatsapp-local"
    }
  }

  # GeoIP enrichment (optional - requires geoip database)
  # if [client_ip] {
  #   geoip {
  #     source => "client_ip"
  #     target => "geoip"
  #   }
  # }
}

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    
    # Index pattern by service and date
    index => "whatsapp-%{[service]:unknown}-%{+YYYY.MM.dd}"
    
    # Document ID for deduplication
    # document_id => "%{[@metadata][fingerprint]}"
    
    # Template settings
    manage_template => true
    template_name => "whatsapp"
    template_overwrite => false
  }

  # Debug output to stdout (disable in production)
  stdout {
    codec => rubydebug {
      metadata => false
    }
  }

  # Send errors to separate index
  if "error" in [tags] or [log_level] == "ERROR" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "whatsapp-errors-%{+YYYY.MM.dd}"
    }
  }

  # Send slow queries to separate index
  if "slow_query" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "whatsapp-slow-queries-%{+YYYY.MM.dd}"
    }
  }

  # Metrics output (optional - for monitoring Logstash itself)
  # statsd {
  #   host => "statsd"
  #   port => 8125
  #   namespace => "logstash"
  # }
}
